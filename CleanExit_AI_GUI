import sys
import os
import cv2
import numpy as np
from pathlib import Path

from PyQt5.QtWidgets import (
    QApplication, QWidget, QLabel, QPushButton, QFileDialog, QMessageBox,
    QVBoxLayout, QHBoxLayout, QListWidget, QListWidgetItem
)
from PyQt5.QtGui import QPixmap, QImage, QIcon
from PyQt5.QtCore import Qt, QSize

import torch
import torch.nn as nn
from torchvision import models, transforms
from ultralytics import YOLO
from PIL import Image, ExifTags


# -------------------------------------------------------
# EXIF Orientation Fix
# -------------------------------------------------------
def fix_orientation(img_path):
    image = Image.open(img_path)
    try:
        exif = dict(image._getexif().items())
        for orientation in ExifTags.TAGS.keys():
            if ExifTags.TAGS[orientation] == 'Orientation':
                break

        if orientation in exif:
            ori = exif[orientation]
            if ori == 3:
                image = image.rotate(180, expand=True)
            elif ori == 6:
                image = image.rotate(270, expand=True)
            elif ori == 8:
                image = image.rotate(90, expand=True)
    except:
        pass

    return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)



# =====================================================================
#                       ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ ë©”ì¸ í´ë˜ìŠ¤
# =====================================================================
class CleanExitDashboard(QWidget):

    def __init__(self):
        super().__init__()

        # ìœˆë„ìš° ì„¤ì •
        self.setWindowTitle("CleanExit ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ")
        self.setGeometry(100, 100, 1400, 900)

        # ì´ë¯¸ì§€ ê²½ë¡œ ì €ì¥
        self.current_image_path = None
        self.base_dir = Path(__file__).resolve().parents[0]

        # ëª¨ë¸ ë¡œë“œ
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
            ),
        ])
        self.class_names = ["clean", "messy"]

        self.classifier_model = self.load_classifier_model()
        self.yolo_model = self.load_yolo_model()

        # -----------------------------------------------------------------------------
        # UI êµ¬ì„±
        # -----------------------------------------------------------------------------
        # ë©”ì¸ ì´ë¯¸ì§€ ì˜ì—­
        self.main_image_label = QLabel("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”")
        self.main_image_label.setAlignment(Qt.AlignCenter)
        self.main_image_label.setStyleSheet("background-color: #2e2e2e; color: white;")
        self.main_image_label.setMinimumSize(1000, 700)

        # ë°© ë²ˆí˜¸ ë¼ë²¨
        self.room_label = QLabel("ë°© ë²ˆí˜¸: -")
        self.room_label.setStyleSheet("font-size: 18px;")

        # ìƒíƒœ ë¼ë²¨
        self.status_label = QLabel("ìƒíƒœ: -")
        self.status_label.setStyleSheet("font-size: 22px; font-weight: bold;")

        left_layout = QVBoxLayout()
        left_layout.addWidget(self.main_image_label)
        left_layout.addWidget(self.room_label)
        left_layout.addWidget(self.status_label)

        # ë¡œê·¸ íŒ¨ë„
        self.log_list = QListWidget()
        self.log_list.setIconSize(QSize(90, 90))
        self.log_list.setMaximumWidth(320)
        self.log_list.itemClicked.connect(self.load_from_log)

        # ë²„íŠ¼
        self.btn_upload = QPushButton("ì‚¬ì§„ ì—…ë¡œë“œ")
        self.btn_upload.clicked.connect(self.upload_image)

        self.btn_predict = QPushButton("íŒë‹¨í•˜ê¸°")
        self.btn_predict.clicked.connect(self.predict)

        button_layout = QHBoxLayout()
        button_layout.addWidget(self.btn_upload)
        button_layout.addWidget(self.btn_predict)

        # ë©”ì¸ ë ˆì´ì•„ì›ƒ
        main_layout = QHBoxLayout()
        main_layout.addLayout(left_layout)
        main_layout.addWidget(self.log_list)

        root_layout = QVBoxLayout()
        root_layout.addLayout(main_layout)
        root_layout.addLayout(button_layout)

        self.setLayout(root_layout)

        # ğŸ¨ ìŠ¤íƒ€ì¼ í…Œë§ˆ ì ìš©
        self.apply_theme()



    # =====================================================================
    #                             í…Œë§ˆ ì ìš©
    # =====================================================================
    def apply_theme(self):
        self.setStyleSheet("""
            QWidget {
                background-color: #1E1E1E;
                color: #E0E0E0;
                font-family: 'Apple SD Gothic Neo', 'Segoe UI', sans-serif;
            }

            QLabel {
                color: #EAEAEA;
                font-size: 16px;
            }

            QPushButton {
                background-color: #2D2D30;
                border: 1px solid #3C3C3C;
                border-radius: 6px;
                padding: 10px;
                color: #FFFFFF;
                font-size: 16px;
            }

            QPushButton:hover {
                background-color: #3C3C3F;
            }

            QPushButton:pressed {
                background-color: #007ACC;
            }

            QListWidget {
                background-color: #252526;
                border: none;
                color: #cccccc;
                font-size: 14px;
            }

            QListWidget::item {
                padding: 12px;
                border-bottom: 1px solid #3C3C3C;
            }

            QListWidget::item:selected {
                background-color: #094771;
                color: #ffffff;
            }

            QScrollBar:vertical {
                background: #2A2A2A;
                width: 12px;
                margin: 0px;
            }
            QScrollBar::handle:vertical {
                background: #4B4B4B;
                min-height: 20px;
                border-radius: 5px;
            }
            QScrollBar::handle:vertical:hover {
                background: #5D5D5D;
            }
        """)



    # =====================================================================
    #                             ëª¨ë¸ ë¡œë”©
    # =====================================================================
    def load_classifier_model(self):
        try:
            ckpt_path = self.base_dir / "checkpoints" / "mobilenet_baseline.pth"
            model = models.mobilenet_v3_large(
                weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1
            )
            model.classifier[3] = nn.Linear(model.classifier[3].in_features, 2)

            state = torch.load(ckpt_path, map_location='cpu')
            model.load_state_dict(state)

            model.to(self.device)
            model.eval()
            print("Classifier Loaded")
            return model
        except Exception as e:
            print("Classifier Load Failed:", e)
            return None


    def load_yolo_model(self):
        try:
            model_path = self.base_dir / "runs_cleanexit" / "yolov8n_cleanexit_v1" / "weights" / "best.pt"
            model = YOLO(str(model_path))
            print("YOLO Loaded")
            return model
        except Exception as e:
            print("YOLO Load Failed:", e)
            return None



    # =====================================================================
    #                             UI ê¸°ëŠ¥
    # =====================================================================
    def upload_image(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "ì´ë¯¸ì§€ ì„ íƒ", "", "Image Files (*.jpg *.jpeg *.png)"
        )
        if not file_path:
            return

        self.current_image_path = file_path
        self.room_label.setText(f"ë°© ë²ˆí˜¸: {self.extract_room_number(file_path)}")

        img = fix_orientation(file_path)
        self.show_image(img)


    def show_image(self, img):
        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb.shape
        qimg = QImage(rgb.data, w, h, w * ch, QImage.Format_RGB888)

        pix = QPixmap.fromImage(qimg).scaled(
            self.main_image_label.width(),
            self.main_image_label.height(),
            Qt.KeepAspectRatio,
            Qt.SmoothTransformation
        )
        self.main_image_label.setPixmap(pix)


    def extract_room_number(self, file_path):
        name = os.path.basename(file_path)
        numbers = ''.join([c for c in name if c.isdigit()])
        return numbers if numbers else "Unknown"



    # =====================================================================
    #                       ë¶„ë¥˜ (clean / messy)
    # =====================================================================
    def classify_image(self, img):
        if self.classifier_model is None:
            return "messy", np.array([0, 1])

        tensor = self.transform(img).unsqueeze(0).to(self.device)

        with torch.no_grad():
            logits = self.classifier_model(tensor)
            probs = torch.softmax(logits, dim=1).cpu().numpy()[0]

        idx = int(np.argmax(probs))
        label = self.class_names[idx]
        return label, probs



    # =====================================================================
    #                           YOLO íƒì§€
    # =====================================================================
    def detect_objects(self, img_path):
        try:
            results = self.yolo_model(img_path)[0]
            boxes = []

            for box in results.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                conf = float(box.conf[0])
                cls_id = int(box.cls[0])
                label = results.names[cls_id]
                boxes.append((x1, y1, x2, y2, label, conf))
            return boxes
        except Exception as e:
            print("YOLO detection error:", e)
            return []


    # =====================================================================
    #                           ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    # =====================================================================
    def draw_boxes(self, img, boxes):
        H, W = img.shape[:2]
        thickness = max(2, W // 400)
        font_scale = max(0.7, W / 1200)

        for (x1, y1, x2, y2, label, conf) in boxes:

            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), thickness)

            text = f"{label} {conf:.2f}"
            (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)

            # Text background
            cv2.rectangle(img, (x1, y1 - th - 10), (x1 + tw + 5, y1), (0, 255, 0), -1)

            # Text
            cv2.putText(
                img, text, (x1 + 2, y1 - 5),
                cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), thickness
            )

        return img



    # =====================================================================
    #                           ë¡œê·¸ ì¶”ê°€
    # =====================================================================
    def add_log(self, img_path, result_text):
        item = QListWidgetItem()
        pix = QPixmap(img_path).scaled(90, 90, Qt.KeepAspectRatio, Qt.SmoothTransformation)

        item.setIcon(QIcon(pix))
        item.setText(result_text)
        item.setData(Qt.UserRole, img_path)

        self.log_list.insertItem(0, item)  # ìµœì‹  ë¡œê·¸ê°€ ìœ„ë¡œ ì˜¬ë¼ì˜¤ê²Œ



    # =====================================================================
    #                         ë¡œê·¸ì—ì„œ ë‹¤ì‹œ ë¡œë“œ
    # =====================================================================
    def load_from_log(self, item):
        img_path = item.data(Qt.UserRole)
        img = fix_orientation(img_path)
        self.show_image(img)



    # =====================================================================
    #                           íŒë‹¨í•˜ê¸°
    # =====================================================================
    def predict(self):
        if not self.current_image_path:
            QMessageBox.warning(self, "ì˜¤ë¥˜", "ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
            return

        img = fix_orientation(self.current_image_path)
        rgb_for_classifier = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # 1) clean/messy classification
        result, probs = self.classify_image(rgb_for_classifier)
        self.status_label.setText(f"ìƒíƒœ: {result.upper()}   clean={probs[0]:.2f}, messy={probs[1]:.2f}")

        # 2) YOLO detection only if messy
        if result == "messy":
            boxes = self.detect_objects(self.current_image_path)
            img = self.draw_boxes(img, boxes)

        # GUI display
        self.show_image(img)

        # Add to log
        room = self.extract_room_number(self.current_image_path)
        self.add_log(self.current_image_path, f"[{room}] {result}")



# =====================================================================
#                               ì‹¤í–‰ ë¶€ë¶„
# =====================================================================
if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = CleanExitDashboard()
    window.show()
    sys.exit(app.exec_())
